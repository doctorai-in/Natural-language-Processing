{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-pretrained-NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BINfboLPqcO_"
      },
      "source": [
        "example_document = '''Baidu's Apollo Project is one of the world's leading autonomous driving and AI programs, with one of the largest partner ecosystems and over 100 global partners as of 2018, including BYD, Dongfeng, Microsoft, Intel, Nvidia, Daimler AG, ZTE, Grab, Ford, Hyundai and Honda.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btx1denTqF1_"
      },
      "source": [
        "# GATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvmXB7UKqIeg"
      },
      "source": [
        "import requests\n",
        "url = \"https://cloud-api.gate.ac.uk/process-document/annie-named-entity-recognizer\"\n",
        "headers = {'Content-Type': 'text/plain'}\n",
        "response = requests.post(url, data=example_document, headers=headers).json()\n",
        "\n",
        "import json\n",
        "print(json.dumps(response, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj_XZJgCqfbW"
      },
      "source": [
        "def gate_ner(sentence):\n",
        "  import requests\n",
        "  return [(sentence[entity[\"indices\"][0]:entity[\"indices\"][1]] + f\" ({entity['gender']})\",entity_type) if entity_type == \"Person\" and \"gender\" in entity else (sentence[entity[\"indices\"][0]:entity[\"indices\"][1]],entity_type)  for entity_type,entities in requests.post(\"https://cloud-api.gate.ac.uk/process-document/annie-named-entity-recognizer\", data=sentence, headers={'Content-Type': 'text/plain'}).json()[\"entities\"].items() for entity in entities]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf_a9UIuQoW_"
      },
      "source": [
        "# https://medium.com/@b.terryjack/nlp-pretrained-named-entity-recognition-7caa5cd28d7b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M10blkrErQ28"
      },
      "source": [
        "gate_ner(example_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdHi9MLEt6OB"
      },
      "source": [
        "# NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLtIbPYJuAfe"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r0uSb7LqwKF"
      },
      "source": [
        "def nltk_ner(document):\n",
        "  return {(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPfbUR4QueDe"
      },
      "source": [
        "nltk_ner(example_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjg7Sj3Tt8bz"
      },
      "source": [
        "# Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkg1NC08xVYM"
      },
      "source": [
        "!python3 -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POXB7Nhfe6mv"
      },
      "source": [
        "import spacy\n",
        "sp_lg = spacy.load('en_core_web_lg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghnQyFifqqeX"
      },
      "source": [
        "def spacy_large_ner(document):\n",
        "  return {(ent.text.strip(), ent.label_) for ent in sp_lg(document).ents}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSFSJvVyxOX"
      },
      "source": [
        "spacy_large_ner(example_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy5wwTpCuutS"
      },
      "source": [
        "# Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zkh_P6buwRq"
      },
      "source": [
        "!pip3 install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eEPh4_f9cXN"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "flair_12class = SequenceTagger.load('ner-ontonotes-fast')\n",
        "flair_4class = SequenceTagger.load('ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbzepNzhzVkY"
      },
      "source": [
        "def flair_ner(document, model):\n",
        "  from flair.data import Sentence\n",
        "  s = Sentence(document)\n",
        "  model.predict(s)\n",
        "  entities = s.to_dict(tag_type='ner')\n",
        "  #print(entities)\n",
        "  return [(entity[\"text\"], entity[\"labels\"]) for entity in entities[\"entities\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kcqsnNbz6h9"
      },
      "source": [
        "flair_ner(example_document, flair_4class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJsXDyy005ys"
      },
      "source": [
        "flair_ner(example_document, flair_12class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOO_vNe32Ze6"
      },
      "source": [
        "# Deep Pavlov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xLK6na62sY1"
      },
      "source": [
        "!pip3 install deeppavlov\n",
        "!python3 -m deeppavlov install ner_ontonotes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q21tWNcOivCQ"
      },
      "source": [
        "from deeppavlov import configs, build_model\n",
        "deeppavlov_ner = build_model(configs.ner.ner_ontonotes, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2t_l-Lg3hYF"
      },
      "source": [
        "def convert_entities(entities):\n",
        "  ents = set()\n",
        "  for entity,next_entity in zip(entities,entities[1:] + [(\".\",\"O\")]):\n",
        "    word,tag = entity\n",
        "    if tag != \"O\":\n",
        "      ent_position, ent_type = tag.split(\"-\")\n",
        "      if ent_position == \"U\":\n",
        "        ents.add((word,ent_type))\n",
        "      else:\n",
        "        if ent_position == \"B\":\n",
        "          w = word\n",
        "        elif ent_position == \"I\":\n",
        "          w += \" \" + word\n",
        "          if next_entity[1].split(\"-\")[0] != \"I\":\n",
        "            ents.add((w,ent_type))\n",
        "  return ents\n",
        "\n",
        "def dp_ner(sentence):\n",
        "  tokens,tags = deeppavlov_ner([sentence])\n",
        "  return convert_entities([(tok,tg) for token,tag in zip(tokens,tags) for tok,tg in list(zip(token,tag)) ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RozDHFQ6yHv"
      },
      "source": [
        "dp_ner(example_document)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBqxcYavqoah"
      },
      "source": [
        "# Stanford Core NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6in8psMKLMs"
      },
      "source": [
        "!pip3 install nltk==3.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8w7LLsyKAYU"
      },
      "source": [
        "!wget http://nlp.stanford.edu/software/stanford-ner-2015-04-20.zip\n",
        "!unzip stanford-ner-2015-04-20.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSfCCO9PKQ27"
      },
      "source": [
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "jar = \"stanford-ner-2015-04-20/stanford-ner-3.5.2.jar\"\n",
        "model = \"stanford-ner-2015-04-20/classifiers/\" \n",
        "st_3class = StanfordNERTagger(model + \"english.all.3class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
        "st_4class = StanfordNERTagger(model + \"english.conll.4class.distsim.crf.ser.gz\", jar, encoding='utf8') \n",
        "st_7class = StanfordNERTagger(model + \"english.muc.7class.distsim.crf.ser.gz\", jar, encoding='utf8') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYow2ZnRKURv"
      },
      "source": [
        "def stanford_ner(document,model):\n",
        "  if model == 1:\n",
        "    return [(entity,tag) for entity,tag in st_3class.tag(document.split()) if tag != \"O\"]\n",
        "  elif model == 2:\n",
        "    return [(entity,tag) for entity,tag in st_4class.tag(document.split()) if tag != \"O\"]\n",
        "  elif model == 3:\n",
        "    return [(entity,tag) for entity,tag in st_7class.tag(document.split()) if tag != \"O\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3tqJYjGKaaP"
      },
      "source": [
        "stanford_ner(example_document,model=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkPAFGdEOMrl"
      },
      "source": [
        "stanford_ner(example_document,model=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12cZITULOQ6u"
      },
      "source": [
        "stanford_ner(example_document,model=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k7BvEX_t-RL"
      },
      "source": [
        "# Allen NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojRC5XLQu8Ra"
      },
      "source": [
        "!pip3 install allennlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--x6JTNKj0FB"
      },
      "source": [
        "from allennlp.predictors import Predictor\n",
        "al = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5hHwi5puQj"
      },
      "source": [
        "def convert_results(allen_results):\n",
        "  ents = set()\n",
        "  for word, tag in zip(allen_results[\"words\"], allen_results[\"tags\"]):\n",
        "    if tag != \"O\":\n",
        "      ent_position, ent_type = tag.split(\"-\")\n",
        "      if ent_position == \"U\":\n",
        "        ents.add((word,ent_type))\n",
        "      else:\n",
        "        if ent_position == \"B\":\n",
        "          w = word\n",
        "        elif ent_position == \"I\":\n",
        "          w += \" \" + word\n",
        "        elif ent_position == \"L\":\n",
        "          w += \" \" + word\n",
        "          ents.add((w,ent_type))\n",
        "  return ents\n",
        "\n",
        "def allennlp_ner(document):\n",
        "  return convert_results(al.predict(sentence=document))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBSuqZ9Oq-XT"
      },
      "source": [
        "allennlp_ner(example_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2uvc2hb1zrI"
      },
      "source": [
        "# Polyglot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ixzM5Kn12Ae"
      },
      "source": [
        "!pip3 install -U git+https://github.com/aboSamoor/polyglot.git@master\n",
        "!polyglot download embeddings2.en ner2.en\n",
        "from polyglot.text import Text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzUrNQKk2X7O"
      },
      "source": [
        "def polyglot_ner(document):\n",
        "  return {(' '.join(entity),entity.tag.split('-')[-1]) for entity in Text(document).entities}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC9e3KFB3T93"
      },
      "source": [
        "polyglot_ner(example_document)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}